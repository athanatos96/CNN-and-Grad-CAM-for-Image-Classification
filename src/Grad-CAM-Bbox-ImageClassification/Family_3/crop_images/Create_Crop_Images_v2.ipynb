{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5578b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "#from PIL import ImageFile\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b79231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision import models\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3587c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Alex\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM#, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "\n",
    "#from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00332a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_crop import(import_train_folder_dataset,\n",
    "                      Data,\n",
    "                      import_test_folder_dataset,\n",
    "                      Data_test\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad007dc8",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c054d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "                            \n",
    "#torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "BBOX_THRESHOLD = 0.75 # From 0-1\n",
    "\n",
    "PATH = \"D:\\\\Personal\\\\Alex\\\\Uni\\\\MS IA\\\\2 Curso\\\\Fall 2022\\Artificial Intelligence\\\\Projects\\\\Project 1\\\\Models Save\\\\GoogleNet_CAM-Plus-ImgClass_v2\\\\\"\n",
    "save_cropedImg_path = \"D:\\\\Personal\\\\Alex\\\\Uni\\\\MS IA\\\\2 Curso\\\\Fall 2022\\Artificial Intelligence\\\\Projects\\\\Project 1\\\\data\\\\Croped_v2\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f47007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model_save = \"weights_googlenet_0.7763157894736842_best.pt\"\n",
    "model_bbox = torch.load(PATH+model_save, map_location=device).to(device)\n",
    "\n",
    "\n",
    "# Define the Target Layers, for CAM\n",
    "#target_layers = [model_bbox.resnet.layer4[-1]]\n",
    "target_layers = [model_bbox.inception5b.branch4]\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = GradCAM(model=model_bbox, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "\n",
    "model_bbox.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7524fa1",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9309f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the files\n",
    "train_data_path = \"D:/Personal/Alex/Uni/MS IA/2 Curso/Fall 2022/Artificial Intelligence/Projects/Project 1/data/Train\"\n",
    "test_data_path = \"D:/Personal/Alex/Uni/MS IA/2 Curso/Fall 2022/Artificial Intelligence/Projects/Project 1/data/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37dec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.Resize((400, 400)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1019bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dim of Data:  (1149,)\n",
      "Train Dim of Lables:  (1149,)\n",
      "Train Dim of Lables:  (1149,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Jupyter NoteBook Master\\IA Master\\Fall 2022\\Artificial Intelligence\\Final Project\\GoogleNet_CAM-Plus-ImgClass_v2\\functions_crop.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return( np.array(img_data_files),np.array(label_data_files),np.array(img_names_files) )\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "train_data, train_labels, train_names = import_train_folder_dataset(train_data_path)\n",
    "print(\"Train Dim of Data: \", train_data.shape)\n",
    "print(\"Train Dim of Lables: \", train_labels.shape)\n",
    "print(\"Train Dim of Lables: \", train_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac5210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dim of Data:  (380,)\n",
      "Test Dim of Lables:  (380,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Jupyter NoteBook Master\\IA Master\\Fall 2022\\Artificial Intelligence\\Final Project\\GoogleNet_CAM-Plus-ImgClass_v2\\functions_crop.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return( (np.array(img_data_files),np.array(img_data_names)) )\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "test_data, test_names = import_test_folder_dataset(test_data_path)\n",
    "print(\"Test Dim of Data: \", test_data.shape)\n",
    "print(\"Test Dim of Lables: \", test_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47582eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len:  1149\n",
      "Test len:  380\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset object\n",
    "train_Dataset = Data(train_data, train_labels, train_names, img_transform)\n",
    "\n",
    "print(\"Train len: \",len(train_Dataset))\n",
    "\n",
    "# Create the dataset object\n",
    "test_Dataset = Data_test(test_data, test_names, img_transform) # img_transform_2 img_transform\n",
    "\n",
    "print(\"Test len: \",len(test_Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af172312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_Dataset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,             \n",
    "    shuffle=False)\n",
    "\n",
    "# Create the dataloaders\n",
    "test_loader = DataLoader(\n",
    "    test_Dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,             \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ef7e0",
   "metadata": {},
   "source": [
    "# Crop Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11d53f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34dc2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(image, device, cam_function):\n",
    "    # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "    grayscale_cam = cam_function(input_tensor=image.to(device), targets=None)\n",
    "\n",
    "    return grayscale_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da74a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox(heat_img, threshold, dim = (224,224)):\n",
    "    H, W = heat_img.shape\n",
    "    # Create Copy\n",
    "    heat_2 = np.copy(heat_img)\n",
    "    # Apply thershold\n",
    "    heat_2[ heat_2 > threshold ] = 255\n",
    "    heat_2[ heat_2 != 255 ] = 0\n",
    "    \n",
    "    up_bound_coord = -1\n",
    "    down_bound_coord = -1\n",
    "    for i in range(len(heat_2)):\n",
    "        # Uper bound\n",
    "        up_row = heat_2[i]\n",
    "        if(up_bound_coord==-1 and 255 in up_row):\n",
    "            # check if there is image in this row\n",
    "            up_bound_coord = i\n",
    "            \n",
    "        # Lower bound\n",
    "        low_row = heat_2[-(i+1)]\n",
    "        if(down_bound_coord==-1 and 255 in low_row):\n",
    "            # check if there is image in this row\n",
    "            down_bound_coord = len(heat_2) - (i)\n",
    "        \n",
    "    left_bound_coord = -1\n",
    "    right_bound_coord = -1\n",
    "    for i in range(len(heat_2[0])):\n",
    "        # left bound\n",
    "        left_row = heat_2[:,i]\n",
    "        if(left_bound_coord==-1 and 255 in left_row):\n",
    "            # check if there is image in this row\n",
    "            left_bound_coord = i\n",
    "            \n",
    "        # right bound\n",
    "        right_row = heat_2[:,-(i+1)]\n",
    "        if(right_bound_coord==-1 and 255 in right_row):\n",
    "            # check if there is image in this row\n",
    "            right_bound_coord = len(heat_2) - (i)\n",
    "    \n",
    "    return np.array([left_bound_coord*(dim[0]/H), up_bound_coord*(dim[1]/W), right_bound_coord*(dim[0]/H), down_bound_coord*(dim[1]/W)])\n",
    "\n",
    "\n",
    "\n",
    "# Given a set of images, return the croped versions, based on the cams\n",
    "def get_cropped_img_batch_base_on_CAM(batch, device, cam_function, threshold = 0.75):\n",
    "    \n",
    "    size = (batch.shape[2], batch.shape[3])\n",
    "    \n",
    "    \n",
    "    heat_list = get_heatmap(batch, device, cam_function)\n",
    "    \n",
    "    outx = []\n",
    "    outbox = []\n",
    "    for img, heat in zip(batch, heat_list):\n",
    "        box = bbox(heat, threshold = threshold, dim = size)\n",
    "        \n",
    "        # Crop the Img\n",
    "        img_crop = img[:,int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "        \n",
    "        # Resize cropped img to original size\n",
    "        rr = transforms.Compose([transforms.Resize(size)])\n",
    "        img_resize = rr(img_crop)\n",
    "        \n",
    "        outx.append(img_resize)\n",
    "        outbox.append(box)\n",
    "    outx2 = torch.stack(outx, 0)\n",
    "    return outx2, outbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdbbfb",
   "metadata": {},
   "source": [
    "## Crop and Save Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b4d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_images(images, labels, names, path):\n",
    "    for im, lab, nam in zip (images, labels, names):\n",
    "        # Name of the Score\n",
    "        image_score_class = \"Score_\"+str(lab+1)\n",
    "        \n",
    "        path_ = os.path.join(path,image_score_class,nam)\n",
    "        \n",
    "        # Reorder Image axis\n",
    "        reorder_im = np.moveaxis(im, 0, -1)\n",
    "        \n",
    "        # Extend the values to 0-255\n",
    "        reorder_im = reorder_im*255\n",
    "        \n",
    "        # Save Image\n",
    "        cv2.imwrite(path_, reorder_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53fb110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [06:33<00:00,  2.73s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_bbox.eval()\n",
    "for bi, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "    images = data[0].to(device)\n",
    "    labels = data[1].numpy()\n",
    "    names = data[2]\n",
    "    \n",
    "    # Get cropped images\n",
    "    new_images, _ = get_cropped_img_batch_base_on_CAM(images, device, cam, threshold = BBOX_THRESHOLD)#.to(device)\n",
    "    \n",
    "    # Inverse the normalization, and change it to Numpy array\n",
    "    new_images_arr = invTrans(new_images).detach().cpu().numpy()\n",
    "    \n",
    "    # save the images\n",
    "    save_images(new_images_arr, labels, names, save_cropedImg_path+\"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987dfc1",
   "metadata": {},
   "source": [
    "## Crop and Save Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034619b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_images_test(images, names, path):\n",
    "    for im, nam in zip (images, names):\n",
    "        \n",
    "        path_ = os.path.join(path,nam)\n",
    "        \n",
    "        # Reorder Image axis\n",
    "        reorder_im = np.moveaxis(im, 0, -1)\n",
    "        \n",
    "        # Extend the values to 0-255\n",
    "        reorder_im = reorder_im*255\n",
    "        \n",
    "        # Save Image\n",
    "        cv2.imwrite(path_, reorder_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91fd59ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:45<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model_bbox.eval()\n",
    "for bi, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    images = data[0].to(device)\n",
    "    names = data[1]\n",
    "    \n",
    "    # Get cropped images\n",
    "    new_images, _ = get_cropped_img_batch_base_on_CAM(images, device, cam, threshold = BBOX_THRESHOLD)#.to(device)\n",
    "    \n",
    "    # Inverse the normalization, and change it to Numpy array\n",
    "    new_images_arr = invTrans(new_images).detach().cpu().numpy()\n",
    "    \n",
    "    # save the images\n",
    "    save_images_test(new_images_arr, names, save_cropedImg_path+\"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
